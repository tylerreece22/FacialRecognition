{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "successful-swedish",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "temporal-freedom",
   "metadata": {},
   "outputs": [],
   "source": [
    "from res_facenet.models import model_920, model_921\n",
    "model920 = model_920()\n",
    "#model921 = model_921()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "sunset-concentration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_face(anchor_image_path, verification_image_path):\n",
    "    #prepare preprocess pipeline\n",
    "    preprocess_pipelines = [transforms.Resize(224), \n",
    "                           transforms.CenterCrop(224), \n",
    "                           transforms.ToTensor(), \n",
    "                           transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                                                std=[0.229, 0.224, 0.225])]\n",
    "    transform = transforms.Compose(preprocess_pipelines)\n",
    "    topil = transforms.ToPILImage()\n",
    "    totensor = transforms.Compose(preprocess_pipelines[:-1])\n",
    "\n",
    "    # read the image and transform it into tensor then normalize it with our transform function pipeline\n",
    "    anchor_image = transform(Image.open(anchor_image_path)).unsqueeze(0)\n",
    "    verification_image = transform(Image.open(verification_image_path)).unsqueeze(0)\n",
    "\n",
    "    # do forward pass\n",
    "    anchor_image_embed, verification_image_embed = model920(anchor_image), model920(verification_image)\n",
    "\n",
    "    # compute the distance using euclidean distance of image embeddings\n",
    "    euclidean_distance = F.pairwise_distance(anchor_image_embed, verification_image_embed)\n",
    "\n",
    "    # we use 1.5 threshold to decide whether images are genuine or impostor\n",
    "\n",
    "    threshold = 1.5\n",
    "\n",
    "    genuine = euclidean_distance <= threshold\n",
    "\n",
    "    print(genuine.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bacterial-strengthening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "verify_face('./data/me.jpg', './data/me_random/me9.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-nicholas",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}